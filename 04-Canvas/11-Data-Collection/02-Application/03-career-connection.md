---
title: "11: Career Connection"
---

<img style="display: none;" src="https://static.bc-edx.com/data/dl-1-2/m11/lms/img/banner.jpg" alt="lesson banner" />

Great work this week learning how to web scrape! Now let’s discuss web scraping in the workplace. Then, we’ll cover how to tailor a resume for a particular job posting. 

Here’s the Career Connection agenda for today:

* Web Scraping in the Workplace
* Finding Your Career Fit: Tailoring a Resume for a Particular Role
* Interview Prep
* Next Steps

### Web Scraping in the Workplace

When sourcing data for a project, you have lots of options, such as using an API, accessing a database, or web scraping. Many of these options _also_ have options to choose from. If you choose to use web scraping, you can program your own scraper (as you did in this module) or use a third-party web scraper. 

As you’ve come to understand, your role as a data professional will often require you to choose the right tool for the job. This is why some data scientists use web scrapers regularly, and some use them only rarely. It all depends on the project!

So when is web scraping the right choice? One of the major enterprise applications of web scraping is collecting data to gain a competitive advantage. This can involve gathering leads, observing prices, and monitoring consumer sentiment. Another popular use case is machine learning. Web scraping helps data scientists acquire the large volume of data that it takes to improve the accuracy of machine learning algorithms. 

### Finding Your Career Fit: Creating a Competitive Resume

![alt = ""](https://static.bc-edx.com/data/dl-1-2/m11/lms/img/coding-career-application-materials.jpg)

The career team collects a lot of data in order to provide you with the best career advice and assistance. Through discussions with tech employers, we have identified the essential components of an effective resume for a data professional. Following our criteria for writing a competitive resume will help you secure interviews and job offers.

To best serve your needs, we have differentiated the resume criteria according to three common student personas:

* Career starters: students with little to no prior career experience
* Career switchers: students who are pursuing a new industry or professional identity
* Career advancers: students who are pursuing growth in their current industry

Which persona best describes you? Once you have decided, you can click the corresponding link below and review the employer-backed resume criteria that best describes you.

* [Career-Starter Resume Criteria](https://careernetwork.2u.com/resources/employer-ready-criteria-for-data-analysis-career-starters/)
* [Career-Switcher Resume Criteria](https://careernetwork.2u.com/resources/employer-ready-criteria-for-data-analysis-career-switchers/)
* [Career-Advancer Resume Criteria](https://careernetwork.2u.com/resources/employer-ready-criteria-for-data-analysis-career-advancers/)

Now, it is time to build a resume that meets these criteria! Once you’re done, you can **submit it for review via the Career Services tab in the course portal.** This will unlock access to job referrals and a Career Coach. Your Career Coach can help you job search, practice interviewing, network, negotiate salary, and more.

As always, we have lots of resources to help you implement these criteria and create the perfect resume, including the following templates and tools:

* [Data Resume Templates](https://careernetwork.2u.com/resources/resume-template-data-analysis/)

* [Hack Your Resume Workshop](https://careernetwork.2u.com/events/)

* [CEN Plus - Resume Module](https://bit.ly/CENPlus)

Bonus tip: Once you start applying to jobs, consider tailoring your resume to the description of the role you’re applying for. For example, add the technologies mentioned in the job description to the technical skills section of your resume, if appropriate.

> **Interview Prep**
>
> For today’s interview prep, we will look at some case-study-style interview questions. Imagine that a hiring manager presents you with the following scenarios. Read the scenarios, and then consider how you would answer the follow-up questions.
> 
> **Case Study Interview Question Number 1: Price Comparison** 
>
> You recently started working at a major online clothing retailer (Company A) that wants to sell at high volumes to increase profit margins. Company A sells to a niche market so it depends on its product and competitive price to reach the largest possible audience. 
> A few months ago, a major competitor (Company B) entered the online market, and Company A wants to keep an eye on their pricing. 
>You’ve been hired to do the data analysis. Obviously, Company B won’t release all of its pricing information to you in a well-documented API. So you’ll have to scrape the data off of its pages and maintain a database of products, prices, and price changes. 
>
> **Follow-up Questions**
> 1. Would you consider it legal to scrape data from your competitors? 
> Answer: In general, data that is publicly available and not copyrighted is legal to scrape. However, there are unique exceptions. You may want to check out these resources: 
>    * The European Union’s [General Data Protection Regulation](https://ec.europa.eu/info/law/law-topic/data-protection/data-protection-eu_en)
>    * [California Consumer Privacy Act](https://oag.ca.gov/privacy/ccpa)
>    * [Computer Fraud and Abuse Act](https://www.nacdl.org/Landing/ComputerFraudandAbuseAct)
> 
> 2. Can you scrape data behind a login page? 
> Answer: Yes, you can; however, it is significantly more difficult. You need to provide the web application with valid credentials and then navigate to the authenticated portion of the site. In addition, you need to confirm the legality of the process. 
> 
> **Case Study Interview Question Number 2: Airline Tickets** 
>
> FlyCheap is a locally owned tech company with a big idea. Using its browser extension, customers can book flights to travel all over the world on any airline. However, it is facing a problem: Its major competitors change their flight prices multiple times per day. 
> You’ve been hired to improve the functionality of the browser extension by allowing it to pop up with an alert when the price of a flight has dropped. Unfortunately, the Google Flights API was recently dropped, and you can no longer just make an API request. You must get the information yourself. 
> Your first task is to write an application that scrapes data from Kayak, Google Flights, and similar companies. When a flight drops or increases in price, that information will get fed to the browser extension and then on to the end user. 
> 
> **Follow-Up Questions**
>
> 1. Can you extract data from sites not written in English? 
> Answer: Yes! You can extract data in any language. Remember that the material you scrape remains in its original language. 
> 
> 2. Can you republish data and/or information that you scraped from the web? 
> Answer: This is another gray area. Watch out for policies that explicitly forbid redistribution of material, and stay vigilant about citation guidelines. You might be able to freely republish, not republish at all, or republish with limitations and credits to the authors. If you are unsure, get in touch with the owners of the site. 

###  Next Steps

* Consider adding web scraping to the technical skills section of your application materials.
